<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Réalité virtuelle et interaction TD2&3 - MOUNSAMY Yanis,GABOULAUD Tony</title>

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/github-gist.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="toc.min.js"></script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<link rel="stylesheet" href="style.css">

</head>

<body>

<div id="toc"></div>

<div id="content">

<h1>Réalité virtuelle et interaction - MOUNSAMY Yanis,GABOULAUD Tony</h1>

<h2>TD 2 - Suivi de mouvement</h2>

<h3>2. Color tracking</h3>

<p>La première technique de suivi que nous avons mis en œuvre consiste à déterminer la position d'un marqueur coloré (un post-it) dans une vidéo. Afin d'obtenir de meilleurs résultats, nous avons travaillé en espace HSV. Nous avons donc effectué les conversions nécessaires et récupéré sur notre selection les 3 paramètres principaux d'une couleur HSV à savoir Hue, Saturation, Brightness.
</p>

<p>
Nous avons ensuite effectué un seuillage à l'aide de ses trois paramètres et d'une valeur de tolérance réglable avec les flèches haut et bas du clavier. Le résultat du seuillage a été mis dans dans une image en niveau de gris afin d'utiliser la méthode findContour(). Afin de limiter le bruit, nous utilisons les opérateurs morpho-mathématiques d'érosion et de dilatation. Après avoir recupérer le contour de notre postit, nous affichons sa boite englobante. 
</p>

<figure>
	<img src="color_tracking.png" width="500" alt="image" />
	<figcaption>Image Originale, image seuillée, image résultat</figcaption>
</figure>


<h3>3. Face tracking</h3>

<p>Pour cette partie nous nous somme servie de l'algorithme de Viola et Jones, très utilisé pour la détection du visage. En gros, on parcourt l'image afin de retrouver un ensemble de caractéristique propre au visage humain. Cet algorithme étant très couteux, nous avons réduit la zone de recherche. Pour limité la zone de recherche (ROI) à un seul visage nous avons initialisé la variable ROI dans un premier temps à toute l’image occupé, puis l’avons affecté comme nouvelle valeur la boite englobante du premier visage détecté. Cependant en limitant la zone de recherche à la taille exact du visage détecté par l'algo, nous nuisont au bon fonctionnement de ce dernier car pour que celui fonctionne dans des conditions normales il faut que le visage soit bien à l'intérieur de la zone de recherche et non aux extrémités. 
Pour contourné ce problème nous avons aggrandie le rectangle obtenue en multipliant sa taille de 1,5. Second problème qui se pose, c’est si le premier visage détecté est de petite taille (visage très eloigné de la caméra) alors on ne pourra pas détecté un visage en premier plan lorsque le visage du fond sera parti, pour résoudre cela nous réinitialisons la zone de recherche à tout l’écran lorsqu’aucun visage n’est détécté.
 </p>
Par la suite nous avons superposé une paire de lunettes et une barbe sur le visage en essayant de les positionner de façon logique (les yeux se trouve un peu plus haut du milieu du visage et la barbe se situe en bas )
 </p>
 <p>
Voici le résultat obtenu
<figure>

		<img src="face_tracking1.png" width="400" alt="Color" />
		<img src="face_tracking2.png" width="400" alt="Color" />
		<figcaption>Un seul visage détécté à la fois</figcaption>
</figure>	
 </p>





<h2>TD 3 - Immersion visuelle</h2>

<h3>1 - Stéréoscopie</h3>
<h4>1.2 - Stéréo anaglyphe</h4>
<p>//TODO </p>

<h3>2 - Stéréo et tracking</h3>
<h4>2.1 - Calcul de la profondeur</h4>
<p>//TODO </p>


<h3>3 - Client / Serveur VRPN</h3>
<p>//TODO </p>

</div>


<script type="text/javascript">
	$('#toc').toc({
	    'selectors': 'h2,h3,h4', //elements to use as headings
	    'container': 'body', //element to find all selectors in
	    'smoothScrolling': true, //enable or disable smooth scrolling on click
	    'prefix': 'toc', //prefix for anchor tags and class names
	    'onHighlight': function(el) {}, //called when a new section is highlighted 
	    'highlightOnScroll': true, //add class to heading that is currently in focus
	    'highlightOffset': 100, //offset to trigger the next headline
	    'anchorName': function(i, heading, prefix) { //custom function for anchor name
	        return prefix+i;
	    },
	    'headerText': function(i, heading, $heading) { //custom function building the header-item text
	        return $heading.text();
	    },
	'itemClass': function(i, heading, $heading, prefix) { // custom function for item class
	  return $heading[0].tagName.toLowerCase();
	}
	});
</script>

</body>
